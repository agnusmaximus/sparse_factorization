{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/maxlam/env3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "from SparseFactorization.sparse_factorization import *\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define roots of unity\n",
    "def w_n(n):\n",
    "    return np.e**((2 * np.pi * 1j) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.+0.00000000e+00j, 0.+0.00000000e+00j, 0.+0.00000000e+00j,\n",
       "        0.+0.00000000e+00j],\n",
       "       [0.+0.00000000e+00j, 1.+2.44929360e-16j, 0.+0.00000000e+00j,\n",
       "        0.+0.00000000e+00j],\n",
       "       [0.+0.00000000e+00j, 0.+0.00000000e+00j, 1.+2.44929360e-16j,\n",
       "        0.+0.00000000e+00j],\n",
       "       [0.+0.00000000e+00j, 0.+0.00000000e+00j, 0.+0.00000000e+00j,\n",
       "        1.+6.10622664e-16j]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Omegas\n",
    "def Omega_n(n):\n",
    "    values = [w_n(i)**(-i) if i >= 1 else 1 for i in range(n)]\n",
    "    return np.diag(values)\n",
    "\n",
    "Omega_n(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.+0.0000000e+00j,  0.+0.0000000e+00j,  1.+0.0000000e+00j,\n",
       "         0.+0.0000000e+00j],\n",
       "       [ 0.+0.0000000e+00j,  1.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "         1.+2.4492936e-16j],\n",
       "       [ 1.+0.0000000e+00j,  0.+0.0000000e+00j, -1.-0.0000000e+00j,\n",
       "        -0.-0.0000000e+00j],\n",
       "       [ 0.+0.0000000e+00j,  1.+0.0000000e+00j, -0.-0.0000000e+00j,\n",
       "        -1.-2.4492936e-16j]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define B_2 and B_4\n",
    "def B_n(n):\n",
    "    \n",
    "    # Identities\n",
    "    ident = np.eye(n//2)\n",
    "    stacked_idnt = np.concatenate([ident, ident], axis=0)\n",
    "    \n",
    "    # Omegas\n",
    "    o1 = Omega_n(n//2)\n",
    "    o2 = -Omega_n(n//2)\n",
    "    stacked_omeg = np.concatenate([o1, o2], axis=0)\n",
    "    \n",
    "    return np.concatenate([stacked_idnt, stacked_omeg], axis=1)\n",
    "\n",
    "B_n(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.+0.00000000e+00j,  1.+0.00000000e+00j,  1.+0.00000000e+00j,\n",
       "          1.+0.00000000e+00j,  1.+0.00000000e+00j,  1.+0.00000000e+00j,\n",
       "          1.+0.00000000e+00j,  1.+0.00000000e+00j],\n",
       "        [ 1.+0.00000000e+00j,  1.+2.44929360e-16j,  1.+2.44929360e-16j,\n",
       "          1.+4.89858720e-16j, -1.+0.00000000e+00j, -1.-2.44929360e-16j,\n",
       "         -1.-2.44929360e-16j, -1.-4.89858720e-16j],\n",
       "        [ 1.+0.00000000e+00j,  1.+2.44929360e-16j, -1.+0.00000000e+00j,\n",
       "         -1.-2.44929360e-16j,  1.+0.00000000e+00j,  1.+2.44929360e-16j,\n",
       "         -1.+0.00000000e+00j, -1.-2.44929360e-16j],\n",
       "        [ 1.+0.00000000e+00j,  1.+6.10622664e-16j, -1.-2.44929360e-16j,\n",
       "         -1.-8.55552023e-16j, -1.+0.00000000e+00j, -1.-6.10622664e-16j,\n",
       "          1.+2.44929360e-16j,  1.+8.55552023e-16j],\n",
       "        [ 1.+0.00000000e+00j, -1.+0.00000000e+00j,  1.+0.00000000e+00j,\n",
       "         -1.+0.00000000e+00j,  1.+0.00000000e+00j, -1.+0.00000000e+00j,\n",
       "          1.+0.00000000e+00j, -1.+0.00000000e+00j],\n",
       "        [ 1.+0.00000000e+00j, -1.-2.44929360e-16j,  1.+2.44929360e-16j,\n",
       "         -1.-4.89858720e-16j, -1.+0.00000000e+00j,  1.+2.44929360e-16j,\n",
       "         -1.-2.44929360e-16j,  1.+4.89858720e-16j],\n",
       "        [ 1.+0.00000000e+00j, -1.-2.44929360e-16j, -1.+0.00000000e+00j,\n",
       "          1.+2.44929360e-16j,  1.+0.00000000e+00j, -1.-2.44929360e-16j,\n",
       "         -1.+0.00000000e+00j,  1.+2.44929360e-16j],\n",
       "        [ 1.+0.00000000e+00j, -1.-6.10622664e-16j, -1.-2.44929360e-16j,\n",
       "          1.+8.55552023e-16j, -1.+0.00000000e+00j,  1.+6.10622664e-16j,\n",
       "          1.+2.44929360e-16j, -1.-8.55552023e-16j]]),\n",
       " [array([[ 1.+0.00000000e+00j,  0.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           0.+0.00000000e+00j,  1.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           0.+0.00000000e+00j,  0.+0.00000000e+00j],\n",
       "         [ 0.+0.00000000e+00j,  1.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           0.+0.00000000e+00j,  0.+0.00000000e+00j,  1.+2.44929360e-16j,\n",
       "           0.+0.00000000e+00j,  0.+0.00000000e+00j],\n",
       "         [ 0.+0.00000000e+00j,  0.+0.00000000e+00j,  1.+0.00000000e+00j,\n",
       "           0.+0.00000000e+00j,  0.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           1.+2.44929360e-16j,  0.+0.00000000e+00j],\n",
       "         [ 0.+0.00000000e+00j,  0.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           1.+0.00000000e+00j,  0.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           0.+0.00000000e+00j,  1.+6.10622664e-16j],\n",
       "         [ 1.+0.00000000e+00j,  0.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           0.+0.00000000e+00j, -1.-0.00000000e+00j, -0.-0.00000000e+00j,\n",
       "          -0.-0.00000000e+00j, -0.-0.00000000e+00j],\n",
       "         [ 0.+0.00000000e+00j,  1.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           0.+0.00000000e+00j, -0.-0.00000000e+00j, -1.-2.44929360e-16j,\n",
       "          -0.-0.00000000e+00j, -0.-0.00000000e+00j],\n",
       "         [ 0.+0.00000000e+00j,  0.+0.00000000e+00j,  1.+0.00000000e+00j,\n",
       "           0.+0.00000000e+00j, -0.-0.00000000e+00j, -0.-0.00000000e+00j,\n",
       "          -1.-2.44929360e-16j, -0.-0.00000000e+00j],\n",
       "         [ 0.+0.00000000e+00j,  0.+0.00000000e+00j,  0.+0.00000000e+00j,\n",
       "           1.+0.00000000e+00j, -0.-0.00000000e+00j, -0.-0.00000000e+00j,\n",
       "          -0.-0.00000000e+00j, -1.-6.10622664e-16j]]),\n",
       "  array([[ 1.+0.0000000e+00j,  0.+0.0000000e+00j,  1.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  0.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  0.+0.0000000e+00j],\n",
       "         [ 0.+0.0000000e+00j,  1.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           1.+2.4492936e-16j,  0.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  0.+0.0000000e+00j],\n",
       "         [ 1.+0.0000000e+00j,  0.+0.0000000e+00j, -1.-0.0000000e+00j,\n",
       "          -0.-0.0000000e+00j,  0.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  0.+0.0000000e+00j],\n",
       "         [ 0.+0.0000000e+00j,  1.+0.0000000e+00j, -0.-0.0000000e+00j,\n",
       "          -1.-2.4492936e-16j,  0.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  0.+0.0000000e+00j],\n",
       "         [ 0.+0.0000000e+00j,  0.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  1.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           1.+0.0000000e+00j,  0.+0.0000000e+00j],\n",
       "         [ 0.+0.0000000e+00j,  0.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  0.+0.0000000e+00j,  1.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  1.+2.4492936e-16j],\n",
       "         [ 0.+0.0000000e+00j,  0.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  1.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "          -1.-0.0000000e+00j, -0.-0.0000000e+00j],\n",
       "         [ 0.+0.0000000e+00j,  0.+0.0000000e+00j,  0.+0.0000000e+00j,\n",
       "           0.+0.0000000e+00j,  0.+0.0000000e+00j,  1.+0.0000000e+00j,\n",
       "          -0.-0.0000000e+00j, -1.-2.4492936e-16j]]),\n",
       "  array([[ 1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 1., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., -1.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  1., -1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.,  0.,  1., -1.]]),\n",
       "  array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define F_8 and F_4\n",
    "def F_8():\n",
    "    # First b8 factor\n",
    "    B_8 = B_n(8)\n",
    "    \n",
    "    # Stack b4s\n",
    "    B_4 = B_n(4)\n",
    "    rows = []    \n",
    "    for i in range(2):\n",
    "        row = [np.zeros(B_4.shape) for j in range(i)] + [B_4] + [np.zeros(B_4.shape) for j in range(2-i-1)]\n",
    "        rows.append(np.concatenate(row, axis=1))\n",
    "    B_4_factor = np.concatenate(rows, axis=0)\n",
    "    \n",
    "    # Stack b2s\n",
    "    B_2 = B_n(2)\n",
    "    rows = []\n",
    "    for i in range(4):\n",
    "        row = [np.zeros(B_2.shape) for j in range(i)] + [B_2] + [np.zeros(B_2.shape) for j in range(4-i-1)]\n",
    "        rows.append(np.concatenate(row, axis=1))\n",
    "    B_2_factor = np.concatenate(rows, axis=0)\n",
    "    \n",
    "    # Permutation matrix\n",
    "    perm = np.array([\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
    "        [0, 0, 1, 0 ,0 ,0 ,0 ,0],\n",
    "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    return B_8.dot(B_4_factor).dot(B_2_factor).dot(perm), [B_8, B_4_factor, B_2_factor, perm]\n",
    "    \n",
    "F_8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to convert complex matrices into pytorch form (n,m,...,2)\n",
    "def to_pytorch(complex_matrix):\n",
    "    return np.stack([complex_matrix.real, complex_matrix.imag], axis=len(complex_matrix.shape))\n",
    "\n",
    "# Helper to convert complex matrices in pytorch form into numpy\n",
    "def to_numpy(complex_matrix):\n",
    "    newshp = complex_matrix.shape[:-1]\n",
    "    return complex_matrix[:,:,0].reshape(newshp) + complex_matrix[:,:,-1].reshape(newshp)*1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[[1 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 1]\n",
      " [1 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 1]]\n",
      "[[1 0 1 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 1 0 1]]\n",
      "[[1 1 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 1 1]]\n",
      "[[1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]]\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 13.8564, Loss: 13.8564, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0581686, Loss: 0.0581686, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0451091, Loss: 0.0451091, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0330212, Loss: 0.0330212, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0220962, Loss: 0.0220962, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.00433539, Loss: 0.00433539, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0166442, Loss: 0.0166442, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0341495, Loss: 0.0341495, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0743522, Loss: 0.0743522, Variables NNzs: [16, 16, 16, 8], Sum NNzs: 56\n",
      "==================\n",
      "Compare real parts\n",
      "==================\n",
      "Actual 0\n",
      " [[ 1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0. -1. -0. -0. -0.]\n",
      " [ 0.  1.  0.  0. -0. -1. -0. -0.]\n",
      " [ 0.  0.  1.  0. -0. -0. -1. -0.]\n",
      " [ 0.  0.  0.  1. -0. -0. -0. -1.]]\n",
      "Recovered 0\n",
      " [[ 1.002  0.    -0.    -0.    -1.001 -0.    -0.    -0.   ]\n",
      " [ 0.     1.001  0.     0.     0.    -1.002  0.     0.   ]\n",
      " [-0.    -0.     1.001  0.     0.     0.    -1.002 -0.   ]\n",
      " [ 0.     0.     0.     1.002  0.     0.     0.    -1.001]\n",
      " [ 1.002  0.    -0.     0.     1.001  0.     0.     0.   ]\n",
      " [ 0.     1.001  0.     0.    -0.     1.002  0.    -0.   ]\n",
      " [-0.     0.     1.001  0.     0.     0.     1.002  0.   ]\n",
      " [ 0.     0.     0.     1.002  0.    -0.    -0.     1.001]]\n",
      "Actual 1\n",
      " [[ 1.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1. -0.  0.  0.  0.  0.]\n",
      " [ 0.  1. -0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0. -1. -0.]\n",
      " [ 0.  0.  0.  0.  0.  1. -0. -1.]]\n",
      "Recovered 1\n",
      " [[ 1.002 -0.     1.002 -0.    -0.     0.    -0.     0.   ]\n",
      " [-0.    -1.003  0.    -1.002  0.     0.     0.     0.   ]\n",
      " [ 1.003 -0.    -1.003  0.    -0.     0.     0.    -0.   ]\n",
      " [-0.    -1.002  0.     1.002  0.     0.    -0.    -0.   ]\n",
      " [-0.     0.    -0.     0.    -1.003  0.    -1.002  0.   ]\n",
      " [ 0.     0.     0.     0.     0.     1.002  0.     1.002]\n",
      " [-0.     0.     0.    -0.    -1.002  0.     1.002 -0.   ]\n",
      " [ 0.     0.    -0.    -0.     0.     1.002 -0.    -1.003]]\n",
      "Actual 2\n",
      " [[ 1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1. -1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1. -1.]]\n",
      "Recovered 2\n",
      " [[ 1.002  1.002 -0.    -0.    -0.    -0.     0.     0.   ]\n",
      " [-1.001  1.001  0.     0.     0.    -0.     0.     0.   ]\n",
      " [-0.    -0.     1.001  1.001  0.     0.    -0.    -0.   ]\n",
      " [-0.     0.    -1.002  1.002  0.     0.     0.    -0.   ]\n",
      " [ 0.     0.    -0.     0.     1.001  1.001  0.     0.   ]\n",
      " [-0.     0.     0.     0.    -1.002  1.002  0.    -0.   ]\n",
      " [-0.     0.     0.     0.     0.     0.     1.002  1.002]\n",
      " [-0.     0.    -0.     0.     0.    -0.    -1.001  1.001]]\n",
      "Actual 3\n",
      " [[1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]]\n",
      "Recovered 3\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "==================\n",
      "Compare imag parts\n",
      "==================\n",
      "Actual 0\n",
      " [[ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  2.449e-16\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   2.449e-16  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  6.106e-16]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00 -0.000e+00 -0.000e+00\n",
      "  -0.000e+00 -0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00 -0.000e+00 -2.449e-16\n",
      "  -0.000e+00 -0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00 -0.000e+00 -0.000e+00\n",
      "  -2.449e-16 -0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00 -0.000e+00 -0.000e+00\n",
      "  -0.000e+00 -6.106e-16]]\n",
      "Recovered 0\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Actual 1\n",
      " [[ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  2.449e-16  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00 -0.000e+00 -0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00 -0.000e+00 -2.449e-16  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  2.449e-16]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  -0.000e+00 -0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  -0.000e+00 -2.449e-16]]\n",
      "Recovered 1\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Actual 2\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Recovered 2\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Actual 3\n",
      " [[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "Recovered 3\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################################################################\n",
    "# This experiment factorized F8 using fine grained sparsity constraints.  \n",
    "# Given the true factors of F_8, we force all nnzs in the corresponding optimized       \n",
    "# matrix to be 0 if it is also a 0 in the true factor\n",
    "#\n",
    "# E.g: if\n",
    "# F_4_1 = [[1, 0, 1, 0],\n",
    "#          [0, 1, 0, w4],\n",
    "#          [1, 0, -1, 0],\n",
    "#          [0, 1, 0, -w4]\n",
    "# where F_4 = F_4_1 * F_4_2 * F_4_perm\n",
    "# Then we force factor 1 the optimize matrix to have form (enforcing sparsity constraint)\n",
    "# \n",
    "# [[a, 0, b, 0],\n",
    "#  [0, c, 0, d],\n",
    "#  [e, 0, f, 0],\n",
    "#  [0, g, 0, h]\n",
    "#\n",
    "# Since the 0s all match, I call this the fine-grained sparsity constraint\n",
    "    \n",
    "\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import SparseFactorization\n",
    "from SparseFactorization.sparse_factorization import *\n",
    "\n",
    "F_8_matrix, F_8_true_factors = F_8()\n",
    "\n",
    "# Sparsity enforcements\n",
    "B_8_sparsity = (F_8_true_factors[0] != 0) * 1\n",
    "B_4_sparsity = (F_8_true_factors[1] != 0) * 1\n",
    "B_2_sparsity = (F_8_true_factors[2] != 0) * 1\n",
    "\n",
    "# Permutation enforce\n",
    "perm_values = F_8_true_factors[-1]\n",
    "\n",
    "# Dbg\n",
    "print(B_8_sparsity)\n",
    "print(B_4_sparsity)\n",
    "print(B_2_sparsity)\n",
    "print(perm_values)\n",
    "\n",
    "# Constraints to pytorch form\n",
    "B_8_sparsity = to_pytorch(B_8_sparsity)\n",
    "B_4_sparsity = to_pytorch(B_4_sparsity)\n",
    "B_2_sparsity = to_pytorch(B_2_sparsity)\n",
    "perm_values = to_pytorch(perm_values)\n",
    "\n",
    "# Factorize!\n",
    "hyperparameters = {\n",
    "    \"learning_rate\" : 1e-2,\n",
    "    \"l1_parameter\" : 0, \n",
    "    \"pruning_threshold\" : 0, \n",
    "    \"training_iters\" : 8000,\n",
    "    \"log_every\" : 1000,\n",
    "    \n",
    "    # Here we 4 factors (XYZP)\n",
    "    \"matrix_initializations\" : {\n",
    "        0: np.stack([np.eye(8), np.eye(8)], axis=2),\n",
    "        1: np.stack([np.eye(8), np.eye(8)], axis=2),\n",
    "        2: np.stack([np.eye(8), np.eye(8)], axis=2),        \n",
    "        3: np.stack([np.eye(8), np.eye(8)], axis=2),\n",
    "    },\n",
    "    \n",
    "    # Here we apply sparsity constraints according to the sparsity of the butterfly patterns\n",
    "    \"sparsity_constraints\" : {\n",
    "        0:B_8_sparsity,\n",
    "        1:B_4_sparsity,\n",
    "        2:B_2_sparsity,\n",
    "    },\n",
    "    \n",
    "    # Here we apply value constraints to the permutation matrix. P=permutation matrix\n",
    "    \"value_constraints\" : {\n",
    "        3: perm_values\n",
    "    },\n",
    "    \n",
    "    \"is_complex\": True\n",
    "}\n",
    "\n",
    "factorizer = SparseFactorizationWithEnforcedStructurePytorch(hyperparameters=hyperparameters)\n",
    "recovered_factors, details = factorizer.factorize(to_pytorch(F_8_matrix))\n",
    "recovered_factors = [to_numpy(x) for x in recovered_factors]\n",
    "\n",
    "# Visualize each of the recovered_factors and the actual factors\n",
    "plt.figure(1, figsize=(15,15))\n",
    "\n",
    "actual_factors = F_8_true_factors\n",
    "\n",
    "# Put actual and recovered factors side by side\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"Compare real parts\")\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"Actual 0\\n\", actual_factors[0].real)\n",
    "print(\"Recovered 0\\n\", recovered_factors[0].real)\n",
    "\n",
    "print(\"Actual 1\\n\", actual_factors[1].real)\n",
    "print(\"Recovered 1\\n\", recovered_factors[1].real)\n",
    "\n",
    "print(\"Actual 2\\n\", actual_factors[2].real)\n",
    "print(\"Recovered 2\\n\", recovered_factors[2].real)\n",
    "\n",
    "print(\"Actual 3\\n\", actual_factors[3].real)\n",
    "print(\"Recovered 3\\n\", recovered_factors[3].real)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"Compare imag parts\")\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"Actual 0\\n\", actual_factors[0].imag)\n",
    "print(\"Recovered 0\\n\", recovered_factors[0].imag)\n",
    "\n",
    "print(\"Actual 1\\n\", actual_factors[1].imag)\n",
    "print(\"Recovered 1\\n\", recovered_factors[1].imag)\n",
    "\n",
    "print(\"Actual 2\\n\", actual_factors[2].imag)\n",
    "print(\"Recovered 2\\n\", recovered_factors[2].imag)\n",
    "\n",
    "print(\"Actual 3\\n\", actual_factors[3].imag)\n",
    "print(\"Recovered 3\\n\", recovered_factors[3].imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[[1 1 1 1 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0]\n",
      " [1 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1]]\n",
      "[[1 1 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 1 1]]\n",
      "[[1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]]\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 13.8564, Loss: 13.8628, Variables NNzs: [128, 32, 16, 8], Sum NNzs: 184\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 4.74024, Loss: 4.74699, Variables NNzs: [100, 32, 16, 8], Sum NNzs: 156\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0587462, Loss: 0.0654232, Variables NNzs: [64, 28, 12, 8], Sum NNzs: 112\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0681159, Loss: 0.0747856, Variables NNzs: [64, 28, 10, 8], Sum NNzs: 110\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0673845, Loss: 0.0740487, Variables NNzs: [64, 26, 12, 8], Sum NNzs: 110\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0411711, Loss: 0.0478393, Variables NNzs: [64, 24, 10, 8], Sum NNzs: 106\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0727774, Loss: 0.0794492, Variables NNzs: [64, 23, 12, 8], Sum NNzs: 107\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0202529, Loss: 0.0269039, Variables NNzs: [64, 24, 13, 8], Sum NNzs: 109\n",
      "SparseFactorizationWithL1AndPruningPytorch: Frob error: 0.0740778, Loss: 0.0807159, Variables NNzs: [64, 21, 12, 8], Sum NNzs: 105\n",
      "==================\n",
      "Compare real parts\n",
      "==================\n",
      "Actual 0\n",
      " [[ 1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0. -1. -0. -0. -0.]\n",
      " [ 0.  1.  0.  0. -0. -1. -0. -0.]\n",
      " [ 0.  0.  1.  0. -0. -0. -1. -0.]\n",
      " [ 0.  0.  0.  1. -0. -0. -0. -1.]]\n",
      "Recovered 0\n",
      " [[ 0.525  0.524  0.614  0.614  0.528  0.528  0.613  0.615]\n",
      " [ 0.528 -0.526  0.615 -0.613  0.528 -0.528  0.614 -0.615]\n",
      " [ 0.612  0.611 -0.528 -0.529  0.615  0.615 -0.528 -0.528]\n",
      " [ 0.614 -0.612 -0.528  0.528  0.615 -0.615 -0.529  0.528]\n",
      " [ 0.525  0.524  0.614  0.614 -0.528 -0.528 -0.613 -0.615]\n",
      " [ 0.528 -0.526  0.615 -0.613 -0.528  0.528 -0.614  0.615]\n",
      " [ 0.612  0.611 -0.528 -0.529 -0.615 -0.615  0.528  0.528]\n",
      " [ 0.614 -0.612 -0.528  0.528 -0.615  0.615  0.529 -0.528]]\n",
      "Actual 1\n",
      " [[ 1.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1. -0.  0.  0.  0.  0.]\n",
      " [ 0.  1. -0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.  0. -1. -0.]\n",
      " [ 0.  0.  0.  0.  0.  1. -0. -1.]]\n",
      "Recovered 1\n",
      " [[ 1.319e+00  1.741e-03 -1.000e-01  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [-6.084e-04  1.319e+00  0.000e+00 -9.812e-02  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 1.004e-01  0.000e+00  1.318e+00 -1.604e-03  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  1.003e-01  0.000e+00  1.320e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  1.318e+00  0.000e+00\n",
      "  -9.802e-02  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  1.771e-04  1.318e+00\n",
      "   0.000e+00 -1.000e-01]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  1.003e-01  0.000e+00\n",
      "   1.320e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  1.003e-01\n",
      "   1.702e-03  1.318e+00]]\n",
      "Actual 2\n",
      " [[ 1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1. -1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1. -1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1. -1.]]\n",
      "Recovered 2\n",
      " [[ 1.325e+00  1.461e-03  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [-2.917e-03  1.322e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  1.324e+00  6.206e-04  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  1.322e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  1.321e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  1.323e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   1.322e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  -6.783e-04  1.324e+00]]\n",
      "Actual 3\n",
      " [[1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]]\n",
      "Recovered 3\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "==================\n",
      "Compare imag parts\n",
      "==================\n",
      "Actual 0\n",
      " [[ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  2.449e-16\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   2.449e-16  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  6.106e-16]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00 -0.000e+00 -0.000e+00\n",
      "  -0.000e+00 -0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00 -0.000e+00 -2.449e-16\n",
      "  -0.000e+00 -0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00 -0.000e+00 -0.000e+00\n",
      "  -2.449e-16 -0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00 -0.000e+00 -0.000e+00\n",
      "  -0.000e+00 -6.106e-16]]\n",
      "Recovered 0\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Actual 1\n",
      " [[ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  2.449e-16  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00 -0.000e+00 -0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00 -0.000e+00 -2.449e-16  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "   0.000e+00  2.449e-16]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  -0.000e+00 -0.000e+00]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  -0.000e+00 -2.449e-16]]\n",
      "Recovered 1\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Actual 2\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Recovered 2\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Actual 3\n",
      " [[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]]\n",
      "Recovered 3\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################################################################\n",
    "# This experiment factorizes F8 using coarse grained sparsity constraints.  \n",
    "#\n",
    "# Given F_8 =\n",
    "# B_8 [[B4 0],[0, B4]] [[B2, 0, 0, 0], [0, B2, 0, 0], [0, 0, B2, 0], [0, 0, 0, B2]] Perm\n",
    "#\n",
    "# In this experiment we enforce the second and third factor to have 0s as in the form form above.\n",
    "# Since the 0s of the Is in the Bs are not captured these are called coarse grained sparsity constraints.\n",
    "\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import SparseFactorization\n",
    "from SparseFactorization.sparse_factorization import *\n",
    "\n",
    "F_8_matrix, F_8_true_factors = F_8()\n",
    "\n",
    "# Sparsity enforcements\n",
    "#B_8_sparsity = (F_8_true_factors[0] != 0) * 1\n",
    "#B_4_sparsity = (F_8_true_factors[1] != 0) * 1\n",
    "#B_2_sparsity = (F_8_true_factors[2] != 0) * 1\n",
    "\n",
    "# B_8 has no sparsity constraints\n",
    "# B_4 looks like: [B_4 0], [0, B4]\n",
    "B_4_sparsity = np.array([\n",
    "    [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 1, 1, 1, 1],    \n",
    "])\n",
    "\n",
    "B_2_sparsity = np.array([\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 1],    \n",
    "])\n",
    "\n",
    "# Permutation enforce\n",
    "perm_values = F_8_true_factors[-1]\n",
    "\n",
    "# Dbg\n",
    "#print(B_8_sparsity)\n",
    "print(B_4_sparsity)\n",
    "print(B_2_sparsity)\n",
    "print(perm_values)\n",
    "\n",
    "# Constraints to pytorch form\n",
    "#B_8_sparsity = to_pytorch(B_8_sparsity)\n",
    "B_4_sparsity = to_pytorch(B_4_sparsity)\n",
    "B_2_sparsity = to_pytorch(B_2_sparsity)\n",
    "perm_values = to_pytorch(perm_values)\n",
    "\n",
    "# Factorize!\n",
    "hyperparameters = {\n",
    "    \"learning_rate\" : 8e-3,\n",
    "    \"l1_parameter\" : .0001, \n",
    "    \"pruning_threshold\" : 1e-4, \n",
    "    \"training_iters\" : 8000,\n",
    "    \"log_every\" : 1000,\n",
    "    \n",
    "    # Here we 4 factors (XYZP)\n",
    "    \"matrix_initializations\" : {\n",
    "        0: np.stack([np.eye(8), np.eye(8)], axis=2),\n",
    "        1: np.stack([np.eye(8), np.eye(8)], axis=2),\n",
    "        2: np.stack([np.eye(8), np.eye(8)], axis=2),        \n",
    "        3: np.stack([np.eye(8), np.eye(8)], axis=2),\n",
    "    },\n",
    "    \n",
    "    # Here we apply sparsity constraints according to the sparsity of the butterfly patterns\n",
    "    \"sparsity_constraints\" : {\n",
    "        #0:B_8_sparsity,\n",
    "        1:B_4_sparsity,\n",
    "        2:B_2_sparsity,\n",
    "    },\n",
    "    \n",
    "    # Here we apply value constraints to the permutation matrix. P=permutation matrix\n",
    "    \"value_constraints\" : {\n",
    "        3: perm_values\n",
    "    },\n",
    "    \n",
    "    \"is_complex\": True\n",
    "}\n",
    "\n",
    "factorizer = SparseFactorizationWithEnforcedStructurePytorch(hyperparameters=hyperparameters)\n",
    "recovered_factors, details = factorizer.factorize(to_pytorch(F_8_matrix))\n",
    "recovered_factors = [to_numpy(x) for x in recovered_factors]\n",
    "\n",
    "# Visualize each of the recovered_factors and the actual factors\n",
    "plt.figure(1, figsize=(15,15))\n",
    "\n",
    "actual_factors = F_8_true_factors\n",
    "\n",
    "# Put actual and recovered factors side by side\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"Compare real parts\")\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"Actual 0\\n\", actual_factors[0].real)\n",
    "print(\"Recovered 0\\n\", recovered_factors[0].real)\n",
    "\n",
    "print(\"Actual 1\\n\", actual_factors[1].real)\n",
    "print(\"Recovered 1\\n\", recovered_factors[1].real)\n",
    "\n",
    "print(\"Actual 2\\n\", actual_factors[2].real)\n",
    "print(\"Recovered 2\\n\", recovered_factors[2].real)\n",
    "\n",
    "print(\"Actual 3\\n\", actual_factors[3].real)\n",
    "print(\"Recovered 3\\n\", recovered_factors[3].real)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"Compare imag parts\")\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"Actual 0\\n\", actual_factors[0].imag)\n",
    "print(\"Recovered 0\\n\", recovered_factors[0].imag)\n",
    "\n",
    "print(\"Actual 1\\n\", actual_factors[1].imag)\n",
    "print(\"Recovered 1\\n\", recovered_factors[1].imag)\n",
    "\n",
    "print(\"Actual 2\\n\", actual_factors[2].imag)\n",
    "print(\"Recovered 2\\n\", recovered_factors[2].imag)\n",
    "\n",
    "print(\"Actual 3\\n\", actual_factors[3].imag)\n",
    "print(\"Recovered 3\\n\", recovered_factors[3].imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
